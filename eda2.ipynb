{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA y liempieza de datos para posterior carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abrir los archivos Json para posterior carpeta(todo esto lo hice en una carpeta que no es donde tengo el repositorio Clonado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se abre el primer archivo\n",
    "rows=[]\n",
    "with open ('australian_user_reviews.json',encoding='MacRoman') as f:  # MacRoman es el tipo de encoding que acepta \n",
    "    for line in f.readlines():\n",
    "        rows.append(ast.literal_eval(line))\n",
    "        \n",
    "df_user=pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se abre el de items\n",
    "rows=[]\n",
    "with open ('australian_users_items.json',encoding='MacRoman') as f:  # MacRoman es el tipo de encoding que acepta \n",
    "    for line in f.readlines():\n",
    "        rows.append(ast.literal_eval(line))\n",
    "        \n",
    "df_items=pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#archivo de steams\n",
    "rows = []\n",
    "with open('output_steam_games.json', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        rows.append(json.loads(line))\n",
    "\n",
    "df_games = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los abrimos para ver su forma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a trabajar primero el df_games "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimino todas las filas que son completamentes nulas\n",
    "df_games_clean=df_games.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hago one-hot-encoding sobre generos \n",
    "df_cleaned = df_games.dropna(subset=['genres'])\n",
    "\n",
    "# Aplicar one-hot encoding a la columna 'genres'\n",
    "genres_dummies = pd.get_dummies(df_cleaned['genres'].apply(pd.Series).stack()).groupby(level=0).sum()\n",
    "\n",
    "# Combinar los datos originales con las columnas codificadas\n",
    "df_encoded = pd.concat([df_cleaned, genres_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elimino las columnas que no voy a utilizar para las futuras funciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded=df_encoded.drop(['title','url','tags','reviews_url','genres','publisher','specs','earlyaccess'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a trabajar con los formatos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trasnformo precios para poder usar price como float para eso saco todo los datos que puede ser strin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar valores en la columna 'price'\n",
    "df_encoded['price'] = df_encoded['price'].replace(['Free to Play', 'Free To Play','Free','0 Demo','Play for 0!','Install Now','Play WARMACHINE: Tactics Demo',\n",
    "                                         '0 Mod','Install Theme','Third-party','Play Now','0 HITMAN™ Holiday Pack','Play the Demo','0 to Try','0 to Use','0 Demo'], '0', regex=True)\n",
    "\n",
    "#Elimino nulos \n",
    "df_encoded['price']=df_encoded['price'].dropna()\n",
    "\n",
    "#Cambio de formato\n",
    "\n",
    "df_encoded['price'] = df_encoded['price'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a trabajar los ID como enteros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded['item_id'] = df_encoded['item_id'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a trabajar las columnas voy a pasar todo a minusculas para ser mas facil validar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Cambiar nombres de columnas a minúsculas\n",
    "df_encoded.columns = df_encoded.columns.str.lower()\n",
    "\n",
    "# Función para eliminar caracteres especiales de una cadena\n",
    "def remove_special_characters(text):\n",
    "    return re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "# Aplicar la función para eliminar caracteres especiales en los nombres de columnas\n",
    "df_encoded.columns = df_encoded.columns.map(remove_special_characters)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame con los nuevos nombres de columnas\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cambia nombre de id a item_id y paso a minuscula la columna developer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.rename(columns={'itemid': 'item_id'}, inplace=True)\n",
    "df_encoded['item_id'] = df_encoded['item_id'].str.rstrip('.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded['developer'] = df_encoded['developer'].str.lower()\n",
    "\n",
    "# Eliminar caracteres extraños (solo conservar letras y números)\n",
    "df_encoded['developer'] = df_encoded['developer'].str.replace('[^a-zA-Z0-9 ]', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a trabajar con items empezando con desanidarla columna items "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items_expanded_list = []\n",
    "\n",
    "#Procesamos cada fila del DataFrame original por separado\n",
    "for idx, row in df_items.iterrows():\n",
    "    # Expandimos la lista de 'items' en una fila en un DataFrame separado\n",
    "    temp = pd.json_normalize(row['items'])\n",
    "    # Agregamos 'user_id' al DataFrame temporal\n",
    "    temp['user_id'] = row['user_id']\n",
    "    # Agregamos el DataFrame temporal a nuestra lista de resultados\n",
    "    df_items_expanded_list.append(temp)\n",
    "\n",
    "# Finalmente, concatenamos todos los DataFrames temporales en uno solo\n",
    "df_items_expanded2 = pd.concat(df_items_expanded_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veo la data \n",
    "df_items_expanded2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elimino las columnas que no voy a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items_expanded2=df_items_expanded2.drop(['item_name','playtime_2weeks'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por el momento dejo items asi y trabajo con user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_expanded_list = []\n",
    "\n",
    "# Luego, procesamos cada fila del DataFrame original por separado\n",
    "for idx, row in df_user.iterrows():\n",
    "    # Expandimos la lista de 'items' en una fila en un DataFrame separado\n",
    "    temp = pd.json_normalize(row['reviews'])\n",
    "    # Agregamos 'user_id' al DataFrame temporal\n",
    "    temp['user_id'] = row['user_id']\n",
    "    # Agregamos el DataFrame temporal a nuestra lista de resultados\n",
    "    df_user_expanded_list.append(temp)\n",
    "\n",
    "# Finalmente, concatenamos todos los DataFrames temporales en uno solo\n",
    "df_user_expanded = pd.concat(df_user_expanded_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_expanded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a crear setiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Inicializa el analizador de sentimiento\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Función para asignar etiquetas de sentimiento a valores numéricos\n",
    "def get_sentiment_label(sentiment_score):\n",
    "    if sentiment_score >= 0.05:\n",
    "        return 2  # Positivo\n",
    "    elif sentiment_score <= -0.05:\n",
    "        return 0  # Malo\n",
    "    else:\n",
    "        return 1  # Neutral\n",
    "\n",
    "# Función para analizar sentimiento y asignar etiquetas numéricas\n",
    "def analyze_sentiment(text):\n",
    "    if not text:  # Verifica si el texto está vacío o None\n",
    "        return 1  # Etiqueta neutral\n",
    "    sentiment_score = sia.polarity_scores(text)['compound']\n",
    "    sentiment_label = get_sentiment_label(sentiment_score)\n",
    "    return sentiment_label\n",
    "\n",
    "# Aplica el análisis de sentimiento a la columna de reseñas y crea una nueva columna\n",
    "df_user_expanded['sentiment_analysis'] = df_user_expanded['review'].apply(analyze_sentiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambio el formato de recommend para usar mas adelante en las funciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_expanded['recommend'] = df_user_expanded['recommend'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformo las fechas para poder trabajar en las funciones elimino nulos para evitar errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar \"Posted\", comas y espacios, y convertir a formato de fecha\n",
    "df_user_expanded['posted'] = df_user_expanded['posted'].str.replace('Posted', '').str.replace(',', '').str.strip()\n",
    "df_user_expanded['posted'] = pd.to_datetime(df_user_expanded['posted'], errors='coerce')\n",
    "\n",
    "# Si solo quieres la fecha en formato de cadena, sin la hora\n",
    "df_user_expanded['posted'] = df_user_expanded['posted'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_cleaned = df_user_expanded.dropna(subset=['posted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar las columnas que no voy a utilizar en mis funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_expanded=df_user_expanded.drop(['funny','last_edited','helpful','review',], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pongo todo los usuarios en minuscula para que se haga mas facil trabajar las funciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_expanded['user_id'] = df_user_expanded['user_id'].str.lower().astype(str)\n",
    "df_items_expanded2['user_id'] = df_items_expanded2['user_id'].str.lower().astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por un tema de rendimiento voy a hacer unas transformaciones en items y trabajar con menos dataframe en las funciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupo los items \n",
    "\n",
    "df_agrupado = df_items_expanded2.groupby('user_id')['item_id'].agg(list).reset_index()\n",
    "\n",
    "#Le agrego item_count y url para tener menos dataframe para trabajar en las funciones\n",
    "df_user=df_user.drop(['reviews'], axis=1)\n",
    "df_final = pd.merge(df_agrupado, df_user, on='user_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo un Dataframe para tener el tiempo jugado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_time=df_items_expanded2.drop(['item_name','playtime_2weeks'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto reduci mucho el peso de mis archivos y buscaba tener la informacion mas comprimida y los guardo en formato parquet para que se reduzca el peso y trabajar bien desde git hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_time=pd.read_parquet('play_time.parquet')\n",
    "df_items_expanded2=pd.read_parquet('item.parquet')\n",
    "df_user_expanded=pd.read_parquet('reviews.parquet')\n",
    "df_encoded=pd.read_parquet('steam.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto son los archivos que voy a utilizar"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
